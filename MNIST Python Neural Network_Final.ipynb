{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST neural network from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully Connected Layer (Linear Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "class Linear():\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.W = np.random.randn(in_size, out_size) * 0.01\n",
    "        self.b = np.zeros((1, out_size))\n",
    "        self.params = [self.W, self.b]\n",
    "        self.gradW = None\n",
    "        self.gradB = None\n",
    "        self.gradInput = None        \n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.output = np.dot(X, self.W) + self.b\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradW = np.dot(self.X.T, nextgrad)\n",
    "        self.gradB = np.sum(nextgrad, axis=0)\n",
    "        self.gradInput = np.dot(nextgrad, self.W.T)\n",
    "        return self.gradInput, [self.gradW, self.gradB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rectified Linear Activation Layer (ReLU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.gradInput = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.output = np.maximum(X, 0)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradInput = nextgrad.copy()\n",
    "        self.gradInput[self.output <=0] = 0\n",
    "        return self.gradInput, []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    def forward(self, X, y):\n",
    "        self.m = y.shape[0]\n",
    "        self.p = softmax(X)\n",
    "        cross_entropy = -np.log(self.p[range(self.m), y]+1e-16)\n",
    "        loss = np.sum(cross_entropy) / self.m\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        y_idx = y.argmax()        \n",
    "        grad = softmax(X)\n",
    "        grad[range(self.m), y] -= 1\n",
    "        grad /= self.m\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "(train_features, train_targets), (test_features, test_targets) = mnist.load_data()\n",
    "\n",
    "\n",
    "train_features = train_features.reshape(60000, 784)\n",
    "print train_features.shape\n",
    "test_features = test_features.reshape(10000, 784)\n",
    "print test_features.shape\n",
    "\n",
    "\n",
    "# # normalize inputs from 0-255 to 0-1\n",
    "train_features = train_features / 255.0\n",
    "test_features = test_features / 255.0\n",
    "\n",
    "print train_targets.shape\n",
    "print test_targets.shape\n",
    "\n",
    "X_train = train_features\n",
    "y_train = train_targets\n",
    "\n",
    "X_val = test_features\n",
    "y_val = test_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAABSCAYAAABwglFkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e75153b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image: [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "# visualizing the first 10 images in the dataset and their labels\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('label for each of the above image: %s' % (y_train[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, we define the container NN class that enables the forward prop and backward propagation of the entire network. Note, how this class enables us to add layers of different types and also correctly pass gradients using the chain rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NN():\n",
    "    def __init__(self, lossfunc=CrossEntropy(), mode='train'):\n",
    "        self.params = []\n",
    "        self.layers = []\n",
    "        self.loss_func = lossfunc\n",
    "        self.grads = []\n",
    "        self.mode = mode\n",
    "        \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        self.params.append(layer.params)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, nextgrad):\n",
    "        self.clear_grad_param()\n",
    "        for layer in reversed(self.layers):\n",
    "            nextgrad, grad = layer.backward(nextgrad)\n",
    "            self.grads.append(grad)\n",
    "        return self.grads\n",
    "    \n",
    "    def train_step(self, X, y):\n",
    "        out = self.forward(X)\n",
    "        loss = self.loss_func.forward(out,y)\n",
    "        nextgrad = self.loss_func.backward(out,y)\n",
    "        grads = self.backward(nextgrad)\n",
    "        return loss, grads\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self.forward(X)\n",
    "        p = softmax(X)\n",
    "        return np.argmax(p, axis=1)\n",
    "    \n",
    "    def predict_scores(self, X):\n",
    "        X = self.forward(X)\n",
    "        p = softmax(X)\n",
    "        return p\n",
    "    \n",
    "    def clear_grad_param(self):\n",
    "        self.grads = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the update function (SGD with momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_params(velocity, params, grads, learning_rate=0.01, mu=0.9):\n",
    "    for v, p, g, in zip(velocity, params, reversed(grads)):\n",
    "        for i in range(len(g)):\n",
    "            v[i] = mu * v[i] - learning_rate * g[i]\n",
    "            p[i] += v[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a function which gives us the minibatches (both the datapoint and the corresponding label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get minibatches\n",
    "def minibatch(X, y, minibatch_size):\n",
    "    n = X.shape[0]\n",
    "    minibatches = []\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    X = X[permutation]\n",
    "    y = y[permutation]\n",
    "    \n",
    "    for i in range(0, n , minibatch_size):\n",
    "        X_batch = X[i:i + minibatch_size, :]\n",
    "        y_batch = y[i:i + minibatch_size, ]\n",
    "        minibatches.append((X_batch, y_batch))\n",
    "        \n",
    "    return minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The traning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu=0.9, X_val=None, y_val=None):\n",
    "    val_loss_epoch = []\n",
    "    minibatches = minibatch(X_train, y_train, minibatch_size)\n",
    "    minibatches_val = minibatch(X_val, y_val, minibatch_size)\n",
    "\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        loss_batch = []\n",
    "        val_loss_batch = []\n",
    "        velocity = []\n",
    "        for param_layer in net.params:\n",
    "            p = [np.zeros_like(param) for param in list(param_layer)]\n",
    "            velocity.append(p)\n",
    "            \n",
    "        # iterate over mini batches\n",
    "        for X_mini, y_mini in minibatches:\n",
    "            loss, grads = net.train_step(X_mini, y_mini)\n",
    "            loss_batch.append(loss)\n",
    "            update_params(velocity, net.params, grads, learning_rate=learning_rate, mu=mu)\n",
    "\n",
    "        for X_mini_val, y_mini_val in minibatches_val:\n",
    "            val_loss, _ = net.train_step(X_mini, y_mini)\n",
    "            val_loss_batch.append(val_loss)\n",
    "        \n",
    "        # accuracy of model at end of epoch after all mini batch updates\n",
    "        m_train = X_train.shape[0]\n",
    "        m_val = X_val.shape[0]\n",
    "        y_train_pred = np.array([], dtype=\"int64\")\n",
    "        y_val_pred = np.array([], dtype=\"int64\")\n",
    "        y_train1 = []\n",
    "        y_vall = []\n",
    "        for i in range(0, m_train, minibatch_size):\n",
    "            X_tr = X_train[i:i + minibatch_size, : ]\n",
    "            y_tr = y_train[i:i + minibatch_size,]\n",
    "            y_train1 = np.append(y_train1, y_tr)\n",
    "            y_train_pred = np.append(y_train_pred, net.predict(X_tr))\n",
    "\n",
    "        for i in range(0, m_val, minibatch_size):\n",
    "            X_va = X_val[i:i + minibatch_size, : ]\n",
    "            y_va = y_val[i:i + minibatch_size,]\n",
    "            y_vall = np.append(y_vall, y_va)\n",
    "            y_val_pred = np.append(y_val_pred, net.predict(X_va))\n",
    "            \n",
    "        train_acc = check_accuracy(y_train1, y_train_pred)\n",
    "        val_acc = check_accuracy(y_vall, y_val_pred)\n",
    "\n",
    "        mean_train_loss = sum(loss_batch) / float(len(loss_batch))\n",
    "        mean_val_loss = sum(val_loss_batch) / float(len(val_loss_batch))\n",
    "        \n",
    "        val_loss_epoch.append(mean_val_loss)\n",
    "        print(\"Loss = {0} | Training Accuracy = {1} | Val Loss = {2} | Val Accuracy = {3}\".format(mean_train_loss, train_acc, mean_val_loss, val_acc))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the accuracy of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoking all that we have created until now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 33.1246386843 | Training Accuracy = 0.0987166666667 | Val Loss = 32.0519844945 | Val Accuracy = 0.098\n",
      "Loss = 33.0678295693 | Training Accuracy = 0.0987166666667 | Val Loss = 32.0519844945 | Val Accuracy = 0.098\n",
      "Loss = 33.1234540911 | Training Accuracy = 0.102183333333 | Val Loss = 33.525638954 | Val Accuracy = 0.101\n",
      "Loss = 33.0967745557 | Training Accuracy = 0.09915 | Val Loss = 32.7888117242 | Val Accuracy = 0.1009\n",
      "Loss = 33.1570104408 | Training Accuracy = 0.102183333333 | Val Loss = 33.525638954 | Val Accuracy = 0.101\n",
      "Loss = 33.0906596161 | Training Accuracy = 0.0973666666667 | Val Loss = 34.8150866061 | Val Accuracy = 0.0982\n",
      "Loss = 33.0948560138 | Training Accuracy = 0.0993 | Val Loss = 33.1572253391 | Val Accuracy = 0.1032\n",
      "Loss = 33.1181179843 | Training Accuracy = 0.102183333333 | Val Loss = 33.525638954 | Val Accuracy = 0.101\n",
      "Loss = 33.1427404909 | Training Accuracy = 0.0993 | Val Loss = 33.1572253391 | Val Accuracy = 0.1032\n",
      "Loss = 33.0856243307 | Training Accuracy = 0.09915 | Val Loss = 32.7888117242 | Val Accuracy = 0.1009\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "## input size\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "## hyperparameters\n",
    "iterations = 10\n",
    "learning_rate = 1e4\n",
    "hidden_nodes = 32\n",
    "output_nodes = 10\n",
    "\n",
    "## define neural net\n",
    "nn = NN()\n",
    "nn.add_layer(Linear(input_dim, hidden_nodes))\n",
    "nn.add_layer(ReLU())\n",
    "nn.add_layer(Linear(hidden_nodes, output_nodes))\n",
    "\n",
    "nn = train(nn, X_train , y_train, minibatch_size=200, epoch=10, \\\n",
    "           learning_rate=learning_rate, X_val=X_val, y_val=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fprop a single image and showing its prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0ff50e1fd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nosJxHysAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0ff5175b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_val[0].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict Scores for each class\n",
    "prediction = nn.predict_scores(X_val[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[7.54278361e-09 5.03649972e-09 2.60172438e-05 4.42434463e-05\n",
      " 2.05711494e-12 3.25863697e-07 1.97742598e-12 9.99928950e-01\n",
      " 1.04155737e-07 3.46676620e-07]\n"
     ]
    }
   ],
   "source": [
    "print \"Scores\"\n",
    "print prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class = nn.predict(X_val[0])[0]\n",
    "predict_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original class\n",
    "y_val[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
